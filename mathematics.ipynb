{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习的数学基础\n",
    "\n",
    "机器学习对于数学要求比较高，但是学习过程中也不能淹没在数学细节中。\t\n",
    " 机器学习的重要的数学基础之一是`线性代数`和`多变量微积分`（`Linear Algebra` and `Multivariable Calculus`）。\t\n",
    " 对于这门学科要掌握到什么程度?请弄懂以下三道试题即可。\n",
    "## 试题一.{Gradients and Hessians}\n",
    "### 题目\n",
    "Recall that a matrix $A \\in {R}^{n \\times n}$ is symmetric if $A^T=A$, that is, ${A}_{ij}={A}_{ji}$ for all $i, j$. Also recall the gradient $\\triangledown f(x)$ of a function $f:{R}^{n} \\rightarrow n$ which is the n-vector of partial derivatives $\\triangledown f(x) = \\begin{bmatrix} \\frac { \\partial  }{ \\partial { x }_{ 1 } }f(x) \\\\ \\vdots \\\\ \\frac { \\partial  }{ \\partial { x }_{ n }}f(x) \\end{bmatrix}$ where $x =  \\begin{bmatrix} {x}_{1} \\\\ \\vdots \\\\ {x}_{n} \\end{bmatrix}$.\t\n",
    " The hessian ${\\triangledown}^{2}f(x)$ of a function $f:{R}^{n} \\rightarrow R$ is the $ n \\times n$ symmetric matrix of twice partial derivatives, $\\begin{bmatrix} \\frac{{\\partial}^{2}}{\\partial {x}_{1}^{2}}f(x) & \\frac{{\\partial}^{2}}{\\partial {x}_{1} {x}_{2}}f(x) & \\cdots & \\frac{{\\partial}^{2}}{\\partial {x}_{1} \\partial {x}_{n}}f(x) \\\\ \\frac{{\\partial}^{2}}{\\partial {x}_{2}{x}_{1}}f(x) & \\frac{{\\partial}^{2}}{\\partial {x}_{2}^{2}}f(x) & \\cdots & \\frac{{\\partial}^{2}}{\\partial {x}_{2} \\partial {x}_{n}}f(x) \\\\ \\vdots & \\vdots & \\ddots &\\vdots \\\\ \\frac{{\\partial}^{2}}{\\partial {x}_{n}{x}_{1}}f(x) & \\frac{{\\partial}^{2}}{\\partial {x}_{n}{x}_{2}}f(x) & \\cdots & \\frac{{\\partial}^{2}}{\\partial {x}_{n}^{2}}f(x) \\end{bmatrix}$. \n",
    "\n",
    "### 第一问\n",
    "Let $f(x)=\\frac{1}{2}{x}^{T}Ax + {b}^{T}x$ where A is a symmetric matrix and $b \\in {R}^{n}$ is a vector. What is $\\triangledown f(x)$?\n",
    "### 解：\n",
    "A可以写成：$A = \\begin{bmatrix} {R}_{1} \\\\ {R}_{2} \\\\ \\cdots \\\\ {R}_{n} \\end{bmatrix}$ 其中 $ {R}_{i} = \\begin{bmatrix} {A}_{i1} & {A}_{i2} & \\cdots & {A}_{in} \\end{bmatrix} $\t\n",
    " 设:$ {f}_{1}(x) = {x}^{T}Ax = {x}^{T}(Ax)={x}^{T}(\\begin{bmatrix} {R}_{1} \\\\ {R}_{2} \\\\ \\cdots \\\\ {R}_{n} \\end{bmatrix}x) = {x}^{T}\\begin{bmatrix} {R}_{1}x \\\\ {R}_{2}x \\\\ \\cdots \\\\ {R}_{n}x \\end{bmatrix} = {x}^{T}\\begin{bmatrix} {R}_{1}x \\\\ {R}_{2}x \\\\ \\cdots \\ {R}_{n}x \\end{bmatrix} $ \t\n",
    " (其中：${R}_{i}$为行向量；$x$为列向量) \t\n",
    " $ = \\begin{bmatrix} {x}_{1} & {x}_{2} &  \\cdots  & {x}_{n}  \\end{bmatrix} \\begin{bmatrix} {R}_{1}x \\\\ {R}_{2}x \\\\ \\vdots \\\\ {R}_{n}x  \\end{bmatrix}  =\\sum_{i=1}^{n}{{x}_{i}{R}_{i}x} =\\sum_{i=1}^{n}{({R}_{i}x){x}_{i}} = \\sum_{i=1}^{n}{\\sum_{j=1}^{n}{{A}_{ij}{x}_{j}}{x}_{i}} = \\sum_{i=1}^{n}{\\sum_{j=1}^{n}{{A}_{ij}{x}_{i}}{x}_{j}} $\t\n",
    " 所以：$\\triangledown {f}_{1}(x)=\\begin{bmatrix} \\frac{\\partial}{\\partial {x}_{1}}({f}_{1}(x)) \\\\ \\frac{\\partial}{\\partial {x}_{2}}({f}_{1}(x)) \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial {x}_{k}}({f}_{1}(x)) \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial {x}_{n}}({f}_{1}(x)) \\\\ \\end{bmatrix} $ \t\n",
    " 通项：$\\frac{\\partial}{\\partial {x}_{k}}({f}_{1}(x))=\\frac{\\partial}{\\partial {x}_{k}}(\\sum_{i=1}^{n}{\\sum_{j=1}^{n}{{A}_{ij}{x}_{i}}{x}_{j}}) = part1 + part2 + part3 + part4$ \t\n",
    "  其中：\t\n",
    " $i = k, j = k$时为part1；\t\n",
    " $i \\neq k, j \\neq k$时为 part2; \t\n",
    " $i = k, j \\neq k$时为 part3; \t\n",
    " $i \\neq k, j = k$时 为 part4 \t\n",
    " 可得：\t\n",
    " $part1 = \\frac{\\partial {A}_{kk}{x}_{k}^{2}}{\\partial {x}_{k}} = 2{A}_{kk}{x}_{k}$;\t\n",
    " $part2 = 0$; \t\n",
    " $part3 = \\frac{\\partial \\sum_{j \\neq k}^{n} {A}_{kj} {x}_{k}{x}_{j}}{{x}_{k}} = \\sum_{j \\neq k}^{n}{A}_{kj}{x}_{j}$; \t\n",
    " $part4 = \\frac{\\partial \\sum_{i \\neq k}^{n} {A}_{ik} {x}_{i}{x}_{k}}{{x}_{k}} = \\sum_{i \\neq k}^{n}{A}_{ik}{x}_{i} = \\sum_{j \\neq k}^{n}{A}_{jk}{x}_{j} = \\sum_{j \\neq k}^{n}{A}_{kj}{x}_{j}$  \t\n",
    " $\\because$ matrix A is symmetric , $\\therefore {A}_{jk} = {A}_{kj}$. \t\n",
    " 可得:$part4=part3$ \t\n",
    " $\\therefore \\frac{\\partial}{\\partial {x}_{k}}({f}_{1}(x)) = part1 + 2part3 = 2{A}_{kk}{x}_{k} + 2\\sum_{j \\neq k}^{n}{A}_{kj}{x}_{j} = 2\\sum_{j = 1}^{n}{A}_{kj}{x}_{j} = 2\\begin{bmatrix} {R}_{1}{x}_{1} \\\\ {R}_{2}{x}_{2} \\\\ \\vdots  \\\\ {R}_{n}{x}_{n}  \\end{bmatrix} \\\\ = 2\\begin{bmatrix} {R}_{1} \\\\ {R}_{2} \\\\ \\vdots \\\\ {R}_{n} \\end{bmatrix}x = 2Ax $\t\n",
    " 综上：$\\frac{\\partial}{\\partial {x}_{k}}({f}_{1}(x)) = 2Ax$ \t\n",
    " 设：${f}_{2}(x) = {b}^Tx = \\sum_{i=1}^{n}{{b}_{i}{x}_{i}}$ \t\n",
    " 则：$\\triangledown{f}_{2}(x) = \\frac{\\partial}{\\partial x} {f}_{2}(x) = \\begin{bmatrix} \\frac{\\partial \\sum_{i=1}^{n}{{b}_{i}{x}_{i}} }{\\partial {x}_{1}} \\\\ \\frac{\\partial \\sum_{i=1}^{n}{{b}_{i}{x}_{i}} }{\\partial {x}_{2}} \\\\ \\vdots \\\\ \\frac{\\partial \\sum_{i=1}^{n}{{b}_{i}{x}_{i}} }{\\partial {x}_{n}} \\\\ \\end{bmatrix} = \\begin{bmatrix} {b}_{1} \\\\ {b}_{2} \\\\ \\vdots \\\\ {b}_{n} \\\\ \\end{bmatrix} = b$\t\n",
    " 结论:$\\triangledown f(x) = \\triangledown {f}_{1}(x) + \\triangledown {f}_{2}(x) = 2Ax + b$ \t\n",
    "### 小结:\n",
    "这是个很形式化的结论，如果A,x,b是标量，我们可轻易得到结论：$\\triangledown (A{x}^{2}+bx) = 2Ax + b$。\t\n",
    " 由本题推算过程可知：这个结论当x为向量时，依然成立，只是 $A{x}^{2}$需表述成：${x}^{T}Ax$,且$A$必须为对称矩阵;$bx$需表述成${b}^{T}x$。\t\n",
    "## 问题2:\n",
    "Let $f(x) = g(h(x))$,where $g:R \\rightarrow R$ is differentiable and $h:{R}^{n} \\rightarrow R$ is differentiable. What is $\\triangledown f(x)$? \t\n",
    "## 解:\t\n",
    "设 $y = h(x)$ $y \\in R$ 则:$f(x) = g(y)$ \t\n",
    "$ \\therefore \\triangledown f(x) = \\frac{d}{dy}g(y)\\frac{\\partial y}{\\partial x} = \\frac{d}{dh}g(h)\\frac{\\partial h}{\\partial x} = \\frac{d}{dh}g(h) \\begin{bmatrix} \\frac{\\partial}{\\partial {x}_{1}}h \\\\ \\frac{\\partial}{\\partial {x}_{2}}h \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial {x}_{n}}h \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{d}{dh}g(h)\\frac{\\partial}{\\partial {x}_{1}}h \\\\ \\frac{d}{dh}g(h)\\frac{\\partial}{\\partial {x}_{2}}h \\\\ \\vdots \\\\ \\frac{d}{dh}g(h)\\frac{\\partial}{\\partial {x}_{n}}h \\\\ \\end{bmatrix} $."
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
